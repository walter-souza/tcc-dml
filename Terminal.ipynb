{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Terminal.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1kBtJkNBwXqDCAIpCizHC8aIR7xziYEH4","authorship_tag":"ABX9TyPnPHcPWgIdiPtHyyZubKOY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"c591e8b4ba7e4fcaae1e687251c2024a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_140db0f00f094aa9a0366a25de31ec7d","IPY_MODEL_cf5c8984d9da4c468df321222d8b245f","IPY_MODEL_79d5bdf6f10d445facf6d7514e5b0655"],"layout":"IPY_MODEL_0df305c4e15b499685f9925c6e3b1b30"}},"140db0f00f094aa9a0366a25de31ec7d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c7983943f08f4f33a6774403ed01cb89","placeholder":"​","style":"IPY_MODEL_9a866f4317694648bbe46a403af42ee1","value":"100%"}},"cf5c8984d9da4c468df321222d8b245f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_16ef4e42881c4742acc8cbc4b2a45ef9","max":8,"min":0,"orientation":"horizontal","style":"IPY_MODEL_50c606699adb495d8ca6253a42884420","value":8}},"79d5bdf6f10d445facf6d7514e5b0655":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c9fc9f0b20df46c9a170e66482866b9c","placeholder":"​","style":"IPY_MODEL_141142cc0e4b431baa940d203858886e","value":" 8/8 [00:18&lt;00:00,  2.02s/it]"}},"0df305c4e15b499685f9925c6e3b1b30":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c7983943f08f4f33a6774403ed01cb89":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9a866f4317694648bbe46a403af42ee1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"16ef4e42881c4742acc8cbc4b2a45ef9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"50c606699adb495d8ca6253a42884420":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c9fc9f0b20df46c9a170e66482866b9c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"141142cc0e4b431baa940d203858886e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d8da1df56bda44a983c473585dd51878":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ee31c60ca93c407a87a9c2f096f68b6a","IPY_MODEL_8e1ff3df11e249f989718c533f541f75","IPY_MODEL_f849a4487f8b409ea1031cc46dfa3237"],"layout":"IPY_MODEL_460660433f1c4ffa9c1afa947f460528"}},"ee31c60ca93c407a87a9c2f096f68b6a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5ab638a0a2aa4e6483a9fa51ab0bfec9","placeholder":"​","style":"IPY_MODEL_212075ade9104fdba8faa11571c7db23","value":"100%"}},"8e1ff3df11e249f989718c533f541f75":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_374064586a7e45629a66193999deba2c","max":8,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7109e6c11a7544f5a29cf27b6b3be862","value":8}},"f849a4487f8b409ea1031cc46dfa3237":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ab32b8c0759c403794f66adbeef7db38","placeholder":"​","style":"IPY_MODEL_f224787e10e045c4b0c8c4fd73f4578c","value":" 8/8 [00:18&lt;00:00,  2.00s/it]"}},"460660433f1c4ffa9c1afa947f460528":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5ab638a0a2aa4e6483a9fa51ab0bfec9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"212075ade9104fdba8faa11571c7db23":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"374064586a7e45629a66193999deba2c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7109e6c11a7544f5a29cf27b6b3be862":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ab32b8c0759c403794f66adbeef7db38":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f224787e10e045c4b0c8c4fd73f4578c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d33ba95fd8634f26bfc21ac7fb4bf362":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2a298c59678f47b29556495e91f022f6","IPY_MODEL_193c6d4c1b5442d0a4d1ddadea9fe04d","IPY_MODEL_4f9b706c0a10441091a13b43d8672f64"],"layout":"IPY_MODEL_f785a4f05f854e3bb14e9a7975b7a082"}},"2a298c59678f47b29556495e91f022f6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d010c935b0264da49c9740fd39e94ac1","placeholder":"​","style":"IPY_MODEL_4809f92fd12a4c15aeaa4e93b3ecf689","value":"100%"}},"193c6d4c1b5442d0a4d1ddadea9fe04d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_478683b02bc84d6188ed973288818156","max":8,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0f666bf3c2cd44cfb982d4db6e74c3cf","value":8}},"4f9b706c0a10441091a13b43d8672f64":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b38ecebdb174465a8ba080f89f83b732","placeholder":"​","style":"IPY_MODEL_22a3098385c34a158097becc3b5a419b","value":" 8/8 [00:18&lt;00:00,  1.99s/it]"}},"f785a4f05f854e3bb14e9a7975b7a082":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d010c935b0264da49c9740fd39e94ac1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4809f92fd12a4c15aeaa4e93b3ecf689":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"478683b02bc84d6188ed973288818156":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f666bf3c2cd44cfb982d4db6e74c3cf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b38ecebdb174465a8ba080f89f83b732":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"22a3098385c34a158097becc3b5a419b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2f2c8fa2c6294a73b54e194df7be7c94":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_78d7e7b4826c42eb8755108ad0eed681","IPY_MODEL_dff3a065bd0c49e394946fa906d97172","IPY_MODEL_c8fe86d9aad243b1a9fc8a505b02fd92"],"layout":"IPY_MODEL_6bed5e8da0c1481bb8a1f3bc71d7c6fb"}},"78d7e7b4826c42eb8755108ad0eed681":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0e64d364a8ba4396b82e6d009f6f2e85","placeholder":"​","style":"IPY_MODEL_4d2e2ef8aebb413ebab8870e852522ef","value":"100%"}},"dff3a065bd0c49e394946fa906d97172":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_50464d5e3c7b4104acaa857ffca4b751","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fe71d598ce204e1e86827deec4df395a","value":2}},"c8fe86d9aad243b1a9fc8a505b02fd92":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_560e747510484799a56ae662adf7a49e","placeholder":"​","style":"IPY_MODEL_bbe83d2e063a4f479e93cb6fc0dc88ef","value":" 2/2 [00:01&lt;00:00,  1.93it/s]"}},"6bed5e8da0c1481bb8a1f3bc71d7c6fb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0e64d364a8ba4396b82e6d009f6f2e85":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4d2e2ef8aebb413ebab8870e852522ef":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"50464d5e3c7b4104acaa857ffca4b751":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fe71d598ce204e1e86827deec4df395a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"560e747510484799a56ae662adf7a49e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bbe83d2e063a4f479e93cb6fc0dc88ef":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"8jk1a9lShxVe"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":3,"metadata":{"id":"pydsO6LSw1HU","executionInfo":{"status":"ok","timestamp":1654093665096,"user_tz":180,"elapsed":1455,"user":{"displayName":"Walter Souza","userId":"13336398162492909212"}}},"outputs":[],"source":["import os\n","os.chdir(\"/content/drive/MyDrive/Facul/TCC/CodigoArtigo/Revisiting_Deep_Metric_Learning_PyTorch-master\")\n","#/content/drive/MyDrive/Facul/TCC/CodigoArtigo/datasets"]},{"cell_type":"code","source":["from google.auth import default\n","from google.colab import auth\n","import gspread\n","\n","auth.authenticate_user()\n","\n","creds, _ = default()\n","gc = gspread.authorize(creds)"],"metadata":{"id":"JV4DsTZpxFF5","executionInfo":{"status":"ok","timestamp":1654093685779,"user_tz":180,"elapsed":15419,"user":{"displayName":"Walter Souza","userId":"13336398162492909212"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["!pip install pretrainedmodels transformers faiss-gpu wandb"],"metadata":{"id":"OLXb6s4A0IhS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#!python main.py --loss margin --batch_mining distance --project DML_Project --group Margin_with_Distance --seed 0 --gpu 0 --bs 112 --data_sampler class_random --samples_per_class 2 --arch resnet50_frozen_normalize --source /content/drive/MyDrive/Facul/TCC/CodigoArtigo/datasets --n_epochs 150 --lr 0.00001 --embed_dim 128 --evaluate_on_gpu"],"metadata":{"id":"jtCAOG4Rzq7A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch, torch.nn as nn"],"metadata":{"id":"oDcSceTEjNJo","executionInfo":{"status":"ok","timestamp":1654093723053,"user_tz":180,"elapsed":4542,"user":{"displayName":"Walter Souza","userId":"13336398162492909212"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"id":"pjPM6P54StS4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#!python main.py --loss margin --arch resnet50_frozen_normalize --batch_mining distance --project DML_Project --group Margin_with_Distance --seed 0 --gpu 0 --bs 112 --n_epochs 20 --lr 0.00001 --embed_dim 16 --data_sampler class_random --samples_per_class 2 --source /content/drive/MyDrive/Facul/TCC/CodigoArtigo/datasets --evaluate_on_gpu"],"metadata":{"id":"vD2y6trIbsET"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python my_main.py --arch distilbert_first --token_max_length 32  --bs 16 --embed_dim 256 --n_epochs 50 --lr 0.00001 --seed 0 --loss margin --dataset garcom --batch_mining distance --project DML_Project --group Margin_with_Distance_First --gpu 0 --data_sampler class_random --samples_per_class 2 --source /content/drive/MyDrive/Facul/TCC/CodigoArtigo/datasets --evaluate_on_gpu"],"metadata":{"id":"NZ2qwVPs0B7w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python my_main.py --arch distilbert_first --token_max_length 64  --bs 32 --embed_dim 256 --n_epochs 50 --lr 0.00001 --log_online --seed 1 --loss margin --dataset garcom --batch_mining distance --project DML_Project --group Margin_with_Distance_First --gpu 0 --data_sampler class_random --samples_per_class 2 --source /content/drive/MyDrive/Facul/TCC/CodigoArtigo/datasets --evaluate_on_gpu"],"metadata":{"id":"OU-OG847J117"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python my_main.py --arch distilbert_first --token_max_length 128  --bs 32 --embed_dim 256 --n_epochs 50 --lr 0.00001 --log_online --seed 2 --loss margin --dataset garcom --batch_mining distance --project DML_Project --group Margin_with_Distance_First --gpu 0 --data_sampler class_random --samples_per_class 2 --source /content/drive/MyDrive/Facul/TCC/CodigoArtigo/datasets --evaluate_on_gpu"],"metadata":{"id":"-m3ch9UoJ1z8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"zY3_RoPHJ1xi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python my_main.py --arch distilbert_all --token_max_length 32  --bs 32 --embed_dim 256 --n_epochs 50 --lr 0.00001 --seed 0 --loss margin --dataset garcom --batch_mining distance --project DML_Project --group Margin_with_Distance_All --gpu 0 --data_sampler class_random --samples_per_class 2 --source /content/drive/MyDrive/Facul/TCC/CodigoArtigo/datasets --evaluate_on_gpu"],"metadata":{"id":"VDI3aim2J1vY","executionInfo":{"status":"ok","timestamp":1654094177123,"user_tz":180,"elapsed":1,"user":{"displayName":"Walter Souza","userId":"13336398162492909212"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["!python my_main.py --arch distilbert_all --token_max_length 64  --bs 32 --embed_dim 256 --n_epochs 50 --lr 0.00001 --log_online --seed 1 --loss margin --dataset garcom --batch_mining distance --project DML_Project --group Margin_with_Distance_All --gpu 0 --data_sampler class_random --samples_per_class 2 --source /content/drive/MyDrive/Facul/TCC/CodigoArtigo/datasets --evaluate_on_gpu"],"metadata":{"id":"Vj2hsSl6J1sr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python my_main.py --arch distilbert_all --token_max_length 128  --bs 32 --embed_dim 256 --n_epochs 50 --lr 0.00001 --log_online --seed 2 --loss margin --dataset garcom --batch_mining distance --project DML_Project --group Margin_with_Distance_All --gpu 0 --data_sampler class_random --samples_per_class 2 --source /content/drive/MyDrive/Facul/TCC/CodigoArtigo/datasets --evaluate_on_gpu"],"metadata":{"id":"MeOpfkM7J1pR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"HVcy-ivvJ1ci"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"_fNwNT6jj7r9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python my_main.py --arch distilbert_first --token_max_length 32  --bs 64 --embed_dim 256 --n_epochs 50 --lr 0.00001 --seed 0 --loss margin --dataset biblept --batch_mining distance --project DML_Project_biblept --group Margin_with_Distance_First --gpu 0 --data_sampler class_random --samples_per_class 2 --source /content/drive/MyDrive/Facul/TCC/CodigoArtigo/datasets --evaluate_on_gpu"],"metadata":{"id":"7or7DA_cj7py"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python my_main.py --arch distilbert_first --token_max_length 64  --bs 128 --embed_dim 256 --n_epochs 50 --lr 0.00001 --log_online --seed 1 --loss margin --dataset biblept --batch_mining distance --project DML_Project_biblept --group Margin_with_Distance_First --gpu 0 --data_sampler class_random --samples_per_class 2 --source /content/drive/MyDrive/Facul/TCC/CodigoArtigo/datasets --evaluate_on_gpu"],"metadata":{"id":"KfLncWrSj7YY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python my_main.py --arch distilbert_all --token_max_length 128  --bs 128 --embed_dim 256 --n_epochs 50 --lr 0.00001 --log_online --seed 2 --loss margin --dataset biblept --batch_mining distance --project DML_Project_biblept --group Margin_with_Distance_First --gpu 0 --data_sampler class_random --samples_per_class 2 --source /content/drive/MyDrive/Facul/TCC/CodigoArtigo/datasets --evaluate_on_gpu"],"metadata":{"id":"ELKddSzSoIjJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"Co8eezMXoIgV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python my_main.py --arch distilbert_all --token_max_length 32  --bs 128 --embed_dim 256 --n_epochs 50 --lr 0.00001 --log_online --seed 0 --loss margin --dataset biblept --batch_mining distance --project DML_Project_biblept --group Margin_with_Distance_All --gpu 0 --data_sampler class_random --samples_per_class 2 --source /content/drive/MyDrive/Facul/TCC/CodigoArtigo/datasets --evaluate_on_gpu"],"metadata":{"id":"gCBZACY1oIea"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python my_main.py --arch distilbert_all --token_max_length 64  --bs 128 --embed_dim 256 --n_epochs 50 --lr 0.00001 --log_online --seed 1 --loss margin --dataset biblept --batch_mining distance --project DML_Project_biblept --group Margin_with_Distance_All --gpu 0 --data_sampler class_random --samples_per_class 2 --source /content/drive/MyDrive/Facul/TCC/CodigoArtigo/datasets --evaluate_on_gpu"],"metadata":{"id":"zhoVN2w7oIcQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python my_main.py --arch distilbert_all --token_max_length 128  --bs 128 --embed_dim 256 --n_epochs 50 --lr 0.00001 --log_online --seed 2 --loss margin --dataset biblept --batch_mining distance --project DML_Project_biblept --group Margin_with_Distance_All --gpu 0 --data_sampler class_random --samples_per_class 2 --source /content/drive/MyDrive/Facul/TCC/CodigoArtigo/datasets --evaluate_on_gpu"],"metadata":{"id":"zVKn35K3oIZl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"jPAxvSqKoIW5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#!python my_main.py --token_max_length 128 --loss margin --dataset garcom --arch distilbert --batch_mining distance --project DML_Project --group Margin_with_Distance --seed 0 --gpu 0 --bs 32 --n_epochs 30 --lr 0.00001 --embed_dim 256 --data_sampler class_random --samples_per_class 2 --source /content/drive/MyDrive/Facul/TCC/CodigoArtigo/datasets --evaluate_on_gpu"],"metadata":{"id":"zCvCOWxUseud"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pickle"],"metadata":{"id":"Ejww4XUwGWRw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6w-1wTNKG9rb","executionInfo":{"status":"ok","timestamp":1653262249181,"user_tz":180,"elapsed":468,"user":{"displayName":"Walter Souza","userId":"13336398162492909212"}},"outputId":"6f95c723-99ac-4f64-a184-97cb97f99653"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["architectures\t    LICENSE\t\t\t      README.md\n","batchminer\t    main.py\t\t\t      Result_Evaluations.py\n","criteria\t    metrics\t\t\t      Sample_Runs\n","datasampler\t    Miniconda3-4.5.4-Linux-x86_64.sh  Terminal.ipynb\n","datasets\t    model_save\t\t\t      Testes.ipynb\n","evaluation\t    my_main.py\t\t\t      toy_experiments\n","garcom_data.gsheet  parameters.py\t\t      Training_Results\n","Images\t\t    __pycache__\t\t\t      utilities\n"]}]},{"cell_type":"code","source":["filepath = \"./Training_Results/garcom/GARCOM_DISTILBERT_2022-5-22-22-56-4/hypa.pkl\"\n","loaded_model = pickle.load(open(filepath, 'rb'))"],"metadata":{"id":"Qw1EeHyAGWPb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import DistilBertTokenizerFast\n","import datasets      as datasets"],"metadata":{"id":"dPhD6Ej9GWIw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")"],"metadata":{"id":"h0HpuMPqGWGi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["garcom_dataset = datasets.select(\"garcom\", None, None, tokenizer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1jiCJJWeGWD7","executionInfo":{"status":"ok","timestamp":1653262624512,"user_tz":180,"elapsed":4266,"user":{"displayName":"Walter Souza","userId":"13336398162492909212"}},"outputId":"3888d39a-b68e-4625-ca47-9227cc4fb975"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ASDADS 116\n","ASDADS 24\n"]}]},{"cell_type":"code","source":["labels = garcom_dataset['training'].labels\n","inputs = garcom_dataset['training'].inputs\n","input_ids = garcom_dataset['training'].encodings['input_ids']\n","attention_mask = garcom_dataset['training'].encodings['attention_mask']"],"metadata":{"id":"O-F-OGOnGV8n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["loaded_model."],"metadata":{"id":"kVpfW4GVIGKO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653263259285,"user_tz":180,"elapsed":3,"user":{"displayName":"Walter Souza","userId":"13336398162492909212"}},"outputId":"da2ba6d1-6d22-4a40-bb43-11f426eed374"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Namespace(arch='distilbert', augmentation='base', batch_mining='distance', bs=116, data_batchmatch_bigbs=512, data_batchmatch_ncomps=10, data_d2_coreset_lambda=1, data_gc_coreset_lim=1e-09, data_gc_softened=False, data_idx_full_prec=False, data_mb_lr=1, data_mb_mom=-1, data_sampler='class_random', data_sampler_lowproj_dim=-1, data_sim_measure='euclidean', data_storage_no_update=False, dataset='garcom', decay=0.0004, device=device(type='cuda'), embed_dim=16, evaltypes=['discriminative'], evaluate_on_gpu=True, evaluation_metrics=['e_recall@1', 'e_recall@2', 'e_recall@4', 'nmi', 'f1', 'mAP_1000', 'mAP_lim', 'mAP_c', 'dists@intra', 'dists@inter', 'dists@intra_over_inter', 'rho_spectrum@0', 'rho_spectrum@-1', 'rho_spectrum@1', 'rho_spectrum@2', 'rho_spectrum@10'], fc_lr=-1, gamma=0.3, gpu=[0], group='Margin_with_Distance', kernels=6, log_online=False, loss='margin', loss_angular_alpha=45, loss_angular_npair_ang_weight=2, loss_angular_npair_l2=0.005, loss_arcface_angular_margin=0.5, loss_arcface_feature_scale=16, loss_arcface_lr=0.0005, loss_contrastive_neg_margin=1, loss_contrastive_pos_margin=0, loss_histogram_nbins=65, loss_lifted_l2=0.005, loss_lifted_neg_margin=1, loss_margin_beta=1.2, loss_margin_beta_constant=False, loss_margin_beta_lr=0.0005, loss_margin_margin=0.2, loss_margin_nu=0, loss_multisimilarity_margin=0.1, loss_multisimilarity_neg_weight=40, loss_multisimilarity_pos_weight=2, loss_multisimilarity_thresh=0.5, loss_npair_l2=0.005, loss_proxynca_lrmulti=50, loss_quadruplet_margin_alpha_1=0.2, loss_quadruplet_margin_alpha_2=0.2, loss_snr_margin=0.2, loss_snr_reg_lambda=0.005, loss_softmax_lr=1e-05, loss_softmax_temperature=0.05, loss_softtriplet_gamma=0.1, loss_softtriplet_lambda=8, loss_softtriplet_lrmulti=1, loss_softtriplet_margin_delta=0.01, loss_softtriplet_n_centroids=2, loss_softtriplet_reg_weight=0.2, loss_triplet_margin=0.2, lr=1e-05, miner_distance_lower_cutoff=0.5, miner_distance_upper_cutoff=1.4, miner_rho_distance_cp=0.2, miner_rho_distance_lower_cutoff=0.5, miner_rho_distance_upper_cutoff=1.4, n_classes=2, n_epochs=20, no_train_metrics=False, not_pretrained=False, optim='adam', pretrained=True, project='DML_Project', samples_per_class=2, save_path='/content/drive/MyDrive/Facul/TCC/CodigoArtigo/Revisiting_Deep_Metric_Learning_PyTorch-master/Training_Results/garcom/GARCOM_DISTILBERT_2022-5-22-22-56-4', savename='', scheduler='step', seed=0, source_path='/content/drive/MyDrive/Facul/TCC/CodigoArtigo/datasets/garcom', storage_metrics=['e_recall@1'], tau=[1000], tv_split_by_samples=False, tv_split_perc=0.8, use_tv_split=False, wandb_key='<your_api_key_here>')"]},"metadata":{},"execution_count":55}]},{"cell_type":"code","source":["class IMDbDataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels\n","\n","    def __getitem__(self, idx):\n","        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        item['labels'] = torch.tensor(self.labels[idx])\n","        return item\n","\n","    def __len__(self):\n","        return len(self.labels)"],"metadata":{"id":"3XqEQwQtnqCh","colab":{"base_uri":"https://localhost:8080/","height":235},"executionInfo":{"status":"error","timestamp":1652716542192,"user_tz":180,"elapsed":624,"user":{"displayName":"Walter Souza","userId":"13336398162492909212"}},"outputId":"d56ef6ef-8171-4435-a77f-63aee1104ddf"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-f89645c30031>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mIMDbDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencodings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencodings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencodings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"E8UgHCc9nqni"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"Ygn82ogZnqi3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install transformers datasets"],"metadata":{"id":"g1RkUQXbnqdA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import DistilBertModel, DistilBertConfig\n","\n","# Initializing a DistilBERT configuration\n","configuration = DistilBertConfig(dim=120)\n","print(configuration)\n","\n","# Initializing a model from the configuration\n","model = DistilBertModel(configuration)\n","\n","# Accessing the model configuration\n","configuration = model.config"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vi1Zbty8mwcL","executionInfo":{"status":"ok","timestamp":1652757694259,"user_tz":180,"elapsed":249,"user":{"displayName":"Walter Souza","userId":"13336398162492909212"}},"outputId":"9bc2d769-373a-4325-f363-9e18163d7ecd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["DistilBertConfig {\n","  \"activation\": \"gelu\",\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 120,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"transformers_version\": \"4.19.2\",\n","  \"vocab_size\": 30522\n","}\n","\n"]}]},{"cell_type":"code","source":["model"],"metadata":{"id":"noBSDIo3mx07"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch, torch.nn as nn"],"metadata":{"id":"YkIDo9_An5Hq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.last_linear = nn.Linear(model.embeddings.word_embeddings.embedding_dim, 16)\n","distilbert_input = {}\n","distilbert_input['input_ids'] = inputs['input_ids']\n","distilbert_input['attention_mask'] = inputs['attention_mask']\n","output = model(**distilbert_input)\n","print(distilbert_input)\n","output.last_hidden_state.shape"],"metadata":{"id":"qvkd6KJWoVyR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652757156886,"user_tz":180,"elapsed":248,"user":{"displayName":"Walter Souza","userId":"13336398162492909212"}},"outputId":"3602d330-c76a-4771-ed6e-8ef290ffa2cd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'input_ids': tensor([[  101,  7592,  1010,  2026,  3899,  2003, 10140,   102, 24873, 10958,\n","         22068, 12871,  2850, 22861,  2497, 13360, 10507,  2278, 13360,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"]},{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 20, 768])"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["from transformers import DistilBertTokenizerFast, DistilBertModel\n","import torch\n","\n","tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\n","model1 = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6i8yID85ojnf","executionInfo":{"status":"ok","timestamp":1652757705964,"user_tz":180,"elapsed":1051,"user":{"displayName":"Walter Souza","userId":"13336398162492909212"}},"outputId":"c88bdf4b-9202-4a78-e48b-7b103e208a06"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_projector.weight']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}]},{"cell_type":"code","source":["model1.last_linear = nn.Linear(model1.config.dim, 120)"],"metadata":{"id":"xQlDxqFbCDtm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"puppOb4KCfTv","executionInfo":{"status":"ok","timestamp":1652760312980,"user_tz":180,"elapsed":288,"user":{"displayName":"Walter Souza","userId":"13336398162492909212"}},"outputId":"ba491d22-31bc-4bd5-b23b-e6616699d488"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DistilBertModel(\n","  (embeddings): Embeddings(\n","    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","    (position_embeddings): Embedding(512, 768)\n","    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (transformer): Transformer(\n","    (layer): ModuleList(\n","      (0): TransformerBlock(\n","        (attention): MultiHeadSelfAttention(\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","        )\n","        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        (ffn): FFN(\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","          (activation): GELUActivation()\n","        )\n","        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      )\n","      (1): TransformerBlock(\n","        (attention): MultiHeadSelfAttention(\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","        )\n","        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        (ffn): FFN(\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","          (activation): GELUActivation()\n","        )\n","        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      )\n","      (2): TransformerBlock(\n","        (attention): MultiHeadSelfAttention(\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","        )\n","        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        (ffn): FFN(\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","          (activation): GELUActivation()\n","        )\n","        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      )\n","      (3): TransformerBlock(\n","        (attention): MultiHeadSelfAttention(\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","        )\n","        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        (ffn): FFN(\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","          (activation): GELUActivation()\n","        )\n","        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      )\n","      (4): TransformerBlock(\n","        (attention): MultiHeadSelfAttention(\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","        )\n","        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        (ffn): FFN(\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","          (activation): GELUActivation()\n","        )\n","        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      )\n","      (5): TransformerBlock(\n","        (attention): MultiHeadSelfAttention(\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","        )\n","        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        (ffn): FFN(\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","          (activation): GELUActivation()\n","        )\n","        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      )\n","    )\n","  )\n","  (last_linear): Linear(in_features=768, out_features=120, bias=True)\n",")"]},"metadata":{},"execution_count":109}]},{"cell_type":"code","source":["model1.config\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0EAOcKEgBokm","executionInfo":{"status":"ok","timestamp":1652757712231,"user_tz":180,"elapsed":2,"user":{"displayName":"Walter Souza","userId":"13336398162492909212"}},"outputId":"a03e1c98-247d-4cf7-bca2-81898483b19c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DistilBertConfig {\n","  \"_name_or_path\": \"distilbert-base-uncased\",\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"transformers_version\": \"4.19.2\",\n","  \"vocab_size\": 30522\n","}"]},"metadata":{},"execution_count":49}]},{"cell_type":"code","source":["input_list = [[\"Hello, my dog is cute\", \"coe raapaziada bbb aaa ccc aaa\"]]\n","inputs = tokenizer(input_list, return_tensors=\"pt\")\n","outputs = model(**inputs)\n","last_hidden_states = outputs.last_hidden_state"],"metadata":{"id":"6Wqx3E-korYM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["inputs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-MY-kQvqGKng","executionInfo":{"status":"ok","timestamp":1652757167664,"user_tz":180,"elapsed":2,"user":{"displayName":"Walter Souza","userId":"13336398162492909212"}},"outputId":"d1697fb7-3eea-48a6-ad5f-b00ed7ca50b7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': tensor([[  101,  7592,  1010,  2026,  3899,  2003, 10140,   102, 24873, 10958,\n","         22068, 12871,  2850, 22861,  2497, 13360, 10507,  2278, 13360,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["last_hidden_states.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NUxj03EJqGV8","executionInfo":{"status":"ok","timestamp":1652652237864,"user_tz":180,"elapsed":6,"user":{"displayName":"Walter Souza","userId":"13336398162492909212"}},"outputId":"25acfdb5-afb0-4a6d-a4ce-1aa8feb6cad7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 19, 768])"]},"metadata":{},"execution_count":57}]},{"cell_type":"code","source":["import torch\n","from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n","\n","tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n","model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")\n","\n","inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n","\n","with torch.no_grad():\n","    logits = model(**inputs).logits\n","\n","predicted_class_id = logits.argmax().item()\n","model.config.id2label[predicted_class_id]\n","model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lecRIvQTtDOC","executionInfo":{"status":"ok","timestamp":1652651861748,"user_tz":180,"elapsed":7018,"user":{"displayName":"Walter Souza","userId":"13336398162492909212"}},"outputId":"cd852740-3284-4907-a4ed-d3ee8146e025"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias', 'pre_classifier.weight', 'pre_classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["2"]},"metadata":{},"execution_count":51}]},{"cell_type":"code","source":["from google.auth import default\n","from google.colab import auth\n","import gspread\n","\n","auth.authenticate_user()\n","\n","creds, _ = default()\n","gc = gspread.authorize(creds)"],"metadata":{"id":"BaLWtTC8t6AM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YcI_9UBqyCTK","executionInfo":{"status":"ok","timestamp":1652652949412,"user_tz":180,"elapsed":7,"user":{"displayName":"Walter Souza","userId":"13336398162492909212"}},"outputId":"651b6aba-70bb-44e0-f20f-91497357dc9b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["drive  sample_data\n"]}]},{"cell_type":"code","source":["worksheet = gc.open('garcom_data').get_worksheet(0)"],"metadata":{"id":"_PLtmBSGxshu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# get_all_values gives a list of rows.\n","rows = worksheet.get_all_values()\n","print(rows)\n","\n","# Convert to a DataFrame and render.\n","import pandas as pd\n","df = pd.DataFrame(rows[1:],columns=rows[0])\n","df = df.drop(['finalizar_pedido'], axis=1)\n","df = df.drop(['endereco_entrega'], axis=1)\n","df = df.drop(['consultar_pedido'], axis=1)\n","df = df.drop(['data'], axis = 1)\n","df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":461},"id":"QrITXcVKxNpU","executionInfo":{"status":"ok","timestamp":1652758074573,"user_tz":180,"elapsed":292,"user":{"displayName":"Walter Souza","userId":"13336398162492909212"}},"outputId":"bc8b28eb-a58a-4e10-85a2-80a6ba175d96"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[['data', 'conjunto', 'ver_cardapio', 'fazer_pedido', 'finalizar_pedido', 'endereco_entrega', 'consultar_pedido'], ['3/31/2022 8:35:25', 'Teste', 'olá! tudo bem? É da pizzaria?', 'Legal, vou querer uma de bacon, mas sem cebola', 'não, só isso mesmo', 'Rua abelinha 110, é casa', 'o que eu pedi até agora?'], ['3/31/2022 11:51:16', 'Teste', 'Boa noite, cardápio por favor ?', 'Uma pizza de calabresa e uma coca.', 'nao', 'Rua Rosa Branca, 220', 'poderia mostrar meu pedido?'], ['3/31/2022 11:57:08', 'Teste', 'Por favor, o menu.', '1 pizza de calabresa e uma pizza de frango', 'somente isso', 'Rua Afonso Pena, 3004', 'o que eu pedi?'], ['4/4/2022 19:18:12', 'Teste', 'coe, manda o menu de hoje', 'quero uma pizza de frango e duas coca, faz favor', 'nao vou querer mais', 'rua lalonge, 945', 'qual o carrinho?'], ['4/4/2022 21:07:50', 'Teste', 'tudo bom? pode me manda o link ou imagem do cardápio', 'quero uma pizza de calabresa, uma de bacon e uma coca-cola', 'nao quero mais nada', 'rua alegrete 1380', 'quais items eu pedi?'], ['3/30/2022 16:02:38', 'Treino', 'Gostaria de ver o cardápio, por favor', 'oie, eu queria pedir uma pizza de Calabresa', 'nao', 'É para entregar Av Afonso Pena 356', 'pode mostrar meus itens??'], ['3/30/2022 16:08:04', 'Treino', 'Ola, eu gostaria de fazer um pedido quais as opções de pizza?', 'Me vê uma pizza de bacon, outra de portuguesa e uma coca-cola', 'nao, apenas isso', 'A entrega é para a Rua da Paz 1001', 'mostra o que eu pedi ai pfvr'], ['3/30/2022 16:16:04', 'Treino', 'Olá, poderia me mostrar o cardapio?', 'Gostaria de uma de Portuguesa e uma Fragon por gentileza', 'nope', 'Rua UFMS, Facom', 'mostra ai as comidas q eu pedi'], ['3/31/2022 11:37:45', 'Treino', 'Poderia mandar o cardápio?', 'Gostaria de uma pizza de Bacon e outra de Calabresa', 'nao senhor', 'Rua Afonso Pena, 3002.', 'quanto deu?'], ['3/31/2022 11:38:59', 'Treino', 'favor o cardápio', '2 pizzas de portuguesa', 'n quero', 'rua ricardo brandao, 171', 'queria saber qnto deu'], ['3/31/2022 11:40:11', 'Treino', 'boa noite, o cardápio por favor', '1 pizza frango e 1 coca-cola', 'n desejo mais nada', 'Rua Rosa Azul, 10', 'pode mostrar qnto deu?'], ['3/31/2022 11:43:28', 'Treino', 'manda o cardapio', '2 pizzas de calabresa e 2 cocas', 'nao, pode encerrar', 'rua rosa amarela, 120', 'qnto ta a conta?'], ['3/31/2022 11:45:35', 'Treino', 'me ve o cardapio', '1 frango, 1 bacon e 1 calabresa', 'somente isso, nao quero mais nada', 'Rua Rosa Branca, 210', 'deu quanto?'], ['3/31/2022 11:49:22', 'Treino', 'me manda o cardápio', 'uma portuguesa e uma bacon com coca', 'apenas isso mesmo', 'Rua Rosa Amarela, 110', 'o que eu pedi?'], ['3/31/2022 12:00:21', 'Treino', 'O cardápio', '1 calabresa e 1 coca', 'nao', 'Rua Ricardo brandao, 2900', 'pode me mostrar meu pedido?'], ['4/1/2022 12:26:02', 'Treino', 'tem menu?', 'manda uma de bacon + frango faz favor ', 'nao quero mais nada', 'rua super mario, 1985', 'mostra meu pedido ai'], ['4/4/2022 19:13:50', 'Treino', 'me ve o cardapio ai, pfv', 'quero uma pizza de bacon e uma  de calabresa', 'apenas esses itens', 'rua do balacobaco, 123', 'quero saber meu pedido'], ['4/4/2022 20:45:07', 'Treino', 'pode mandar foto do cardápio?', 'gostaria de uma pizza de presunto ', 'nao quero, to pobre', 'Av Afonso Pena 350', 'quero saber o q to levando'], ['4/4/2022 20:45:49', 'Treino', 'passo cardápiozao ai', 'me ve duas pizzazona portuguesa', 'pode ser só isso mesmo', 'Rua alibemlonjao, 832', 'consultar pedido'], ['4/4/2022 20:46:12', 'Treino', 'gostaria do cardápio por favor', 'quero uma pizza de calabresa e uma coca cola', 'não vou querer mais nada', 'rua goias 1495', 'posso ver meu pedido?'], ['4/4/2022 20:47:16', 'Treino', 'queria o cardápio', 'quero uma pizza de frango', 'ja tem bastante coisa, n quero mais', 'av mato grosso 560', 'posso ver os itens?'], ['4/4/2022 20:47:52', 'Treino', 'manda foto do cardápio', 'uma pizza de portuguesa e uma de calabresa', 'pode finalizar', 'rua quinze de novembro 354', 'qnto deu até agora?'], ['4/4/2022 20:48:37', 'Treino', 'foto do cardápio por favor', 'uma de frango ', 'apenas isso dai', 'rua Pernambuco 2036', 'qnto to te devendo?'], ['4/4/2022 20:48:46', 'Treino', 'ai patrão, pode me mandar o Menu?', 'cara, me ve uma pizza de frango , na moral', 'apenas isso mesmo', 'na Rua naotalongenao, 367', 'mostra ai o prejuizo'], ['4/4/2022 20:49:32', 'Treino', 'cardápio por favor', 'uma pizza de calabresa e uma coca-cola', 'pode ser só', 'rua maracaju 1595', 'qnto deu de prejuizo?'], ['4/4/2022 20:51:49', 'Treino', 'pode mostrar o cardápio ?', 'uma pizza de bacon e uma coca-cola', 'nada mais', 'rua ana luiza 218', 'posso ver o prejuizo?'], ['4/4/2022 20:52:12', 'Treino', 'manda uma fotinha do cardápio ai', 'quero uma coca e uma pizza portuguesa', 'só isso', 'Rua agoratapertim, 985', 'quero saber minha conta'], ['4/4/2022 20:52:30', 'Treino', 'quero ver o cardápio', 'uma coca-cola e uma pizza de bacon', 'não, pode encerrar', 'av gury marques 303', 'quero ver meus itens'], ['4/4/2022 20:53:28', 'Treino', 'gostaria de ver o cardápio', 'uma pizza de portuguesa', 'não vou querer', 'rua ari coelho de oliveira 560', 'quero ver o que to levando'], ['4/4/2022 20:54:19', 'Treino', 'com licença, gostaria de pedir o cardápio, por favor', 'adoraria uma pizza de bacon e uma coca cola', 'nao to afim', 'rua ruanaoavenida, 548', 'meu pedido'], ['4/4/2022 20:54:21', 'Treino', 'por gentileza, poderia estar enviando o cardápio?', 'quero um pizza de frango', 'nao quero', 'rua portugal 1345', 'meus itens'], ['4/4/2022 20:54:56', 'Treino', 'pode me mandar foto do que tem no cardápio?', 'quero uma coca-cola', 'nao senhor', 'rua dr mario correa 340', 'qnto to levando?'], ['4/4/2022 20:55:41', 'Treino', 'cardápio por favor', 'gostaria de pedir uma pizza de calabresa', 'nao precisa', 'rua marechal rondon 738', 'posso consultar o pedido?'], ['4/4/2022 20:56:05', 'Treino', 'ow, da o cardápio ai', 'da 2 pizza portuguesa e uma de bacon com 3 cocas ', 'pode encerrar', 'rua ruaqueexiste, 321', 'vou morrer em quanto nisso?'], ['4/4/2022 20:56:29', 'Treino', 'me mande o cardápio por favor', 'uma pizza de calabresa e uma coca-cola', 'nao, isso é só', 'rua jose antonio 765', 'até agora deu quanto?'], ['4/4/2022 20:57:17', 'Treino', 'foto do cardápio por gentileza', 'uma coca-cola e uma pizza de calabresa', 'nao quero mais nada disso ai', 'rua da liberdade 490', 'cade a conta?'], ['4/4/2022 20:57:43', 'Treino', 'moço, vc pode me dar o cardápio?', 'quero uma de bacon por favor', 'só isso q eu to sem dinheiro', 'rua jorgejorge, 584', 'me mostra a conta?'], ['4/4/2022 20:58:16', 'Treino', 'cardápio meu caro', 'uma coca-cola e uma pizza de bacon', 'nao', 'Av Fernando Correa 1756', 'qual a conta?'], ['4/4/2022 20:58:47', 'Treino', 'me mande o cardápio', 'uma pizza de calabresa e uma de bacon', 'porfavor, só isso', 'rua 14 de julho 639', 'quanto deu?'], ['4/4/2022 20:58:51', 'Treino', 'ai bicho, quero ver o menu de hoje', 'me da uma coca-cola aí e uma pizza portuguesa', 'nao vou querer mais nada desse lugar', 'rua jorjejorji, 843', 'o que eu pedi até agora?'], ['4/4/2022 20:59:27', 'Treino', 'quero o cardápio ', 'uma coca-cola, uma pizza de calabresa e uma de frango', 'ja ta bom, nao quero mais', 'rua 13 de maio 729', 'o que eu pedi?'], ['4/4/2022 20:59:52', 'Treino', 'me daaaaaa o cardápio', 'Hm, vou querer uma pizza de calabresa', 'nao quero mais nada', 'rua jojojorginho, 432', 'pode mostrar meus itens??'], ['4/4/2022 21:00:38', 'Treino', 'quero o menu de hoje', 'me da uma portuguesa', 'nao', 'rua vasco, 234', 'quanto deu?'], ['4/4/2022 21:00:41', 'Treino', 'por gentileza, me mande a foto do cardápio', 'irei pedir uma pizza de frango', 'ja ta ótimo assim', 'rua rui barbo 1720', 'deu quanto?'], ['4/4/2022 21:01:15', 'Treino', 'foto do cardápio meu caro', 'uma pizza de frango por favor', 'nao, pode mandar pro pai', 'rua barao do rio branco 578', 'o que eu pedi?'], ['4/4/2022 21:01:45', 'Treino', 'passa o cardápio de hoje ai', 'quero 3 coca-cola e uma pizza portuguesa ', 'nao quero, to sem dinheiro', 'rua ojogo, 092', 'pode me mostrar meu pedido?'], ['4/4/2022 21:02:13', 'Treino', 'tem link ou foto do cardápio?', 'vou pedir uma pizza de calabresa', 'ta mt caro, só isso msm', 'rua dom aquino 100', 'quero saber meu pedido'], ['4/4/2022 21:03:02', 'Treino', 'quero a imagem do cardápio', 'uma de portuguesa e uma de calabresa', 'isso dai é tudo', 'av afonso pena 345', 'qnto deu até agora?'], ['4/4/2022 21:03:14', 'Treino', 'boa noite, me da o cardápio', 'quero uma pizza portuguesa', 'não, ja estou satisfeito', 'rua perdiojogo, 999', 'posso ver o prejuizo?'], ['4/4/2022 21:04:04', 'Treino', 'po pode mandar a foto do cardápio ai?', 'quero uma pizza de bacon', 'nao quero', 'rua marechal rondo 3456', 'meu pedido'], ['4/4/2022 21:04:40', 'Treino', 'pode ta me mandando o cardápio?', 'uma coca-cola e uma pizza de bacon', 'nao', 'rua terenos 5489', 'vou morrer em quanto nisso?'], ['4/4/2022 21:05:02', 'Treino', 'aopa, bao? me da um cardápio ai', 'quero pedir 2 pizzas de bacon', 'nao precisa', 'rua perderaoojogo, 384', 'qual o carrinho?'], ['4/4/2022 21:05:47', 'Treino', 'quero visualizar o cardápio', 'me da uma pizza de calabresa e uma coca', 'só isso mesmo', 'rua taacabando, 378', 'quanto deu?'], ['4/4/2022 21:06:24', 'Treino', 'tem o link do cardápio?', 'uma pizza de bacon e uma coca-cola', 'nao', 'av salgado filho 190', 'o que eu pedi?'], ['4/4/2022 21:06:36', 'Treino', 'permita-me visualizar o cardápio', 'gostaria de pedir 3 pizzas de bacon', 'por favor, nao quero mais nada', 'rua acabousera, 389', 'qnto to te devendo?'], ['4/4/2022 21:07:11', 'Treino', 'quero a imagem do cardápio meu chefia', 'pizza de calabresa', 'nao', 'avenida dos bandeirantes 1456', 'qnto to levando?'], ['4/4/2022 21:05:44', 'Treino', 'quero a imagem do cardápio meu amigo', 'pizza de calabresa', 'pode finalizar', 'av bandeirantes 4268', 'o que eu pedi até agora?'], ['4/4/2022 21:08:52', 'Teste', 'boa noite, me manda a foto do cardápio', 'quero uma coca-cola e uma pizza de bacon', 'nope', 'av senador mendes canale 214', 'quanto deu?'], ['4/5/2022 13:59:47', 'Teste', 'Pode me mostrar o cardápio, por favor?', 'quero duas pizzas de frango e uma coca', 'pode encerrar', 'rua 7 de setembro, 2022', 'deu quanto?'], ['4/5/2022 14:01:02', 'Teste', 'quero ver o cardápio', 'me passa uma coca', 'nada', 'rua valverde,2043', 'o que eu pedi?'], ['4/5/2022 14:02:03', 'Teste', 'boa noite, qual o cardápio?', 'quero uma pizza de bacon', 'kkk nao ja ta bom', 'av. das naçoes unidas,34343', 'qnto deu até agora?'], ['4/6/2022 13:01:14', 'Treino', 'Manda o cardapio chefia', 'Quero uma de bacon e dez de calabresa', 'nao ', 'Rua ufms 666', 'meu pedido'], ['4/6/2022 20:03:46', 'Treino', 'Gostaria de ver o cardápio, por gentileza.', '1 Bacon', 'Nenhum', 'Rua Bahia, 500', 'pode mostrar meus itens??'], ['4/8/2022 13:37:57', 'Treino', 'Quero ver as opções', 'Uma pizza de bacon e uma coca-cola', 'somente isso mesmo', 'Rua estados unidos 721', 'qnto ta a conta?'], ['4/8/2022 13:38:59', 'Treino', 'Gostaria de ver o menu', 'Vou querer uma de calabresa', 'assim ja ta bom', 'Rua brasil 291', 'quero saber o q to levando'], ['4/8/2022 13:43:55', 'Treino', 'Deixa eu ver o cardápio', 'Uma de frango e duas cocas', 'n', 'Entrega na rua luxemburgo 405', 'cade a conta?'], ['4/8/2022 14:31:40', 'Teste', 'Boa noite, poderia ver cardápio', 'Eu vou querer uma pizza grande de frango e uma coca', 'Não, obrigado', 'Rua São Miguel 32, bairro das laranjeiras', 'o que eu pedi até agora?'], ['4/8/2022 14:33:32', 'Teste', 'Passa o cardápio ae', 'Vou querer uma pizza portuguesa ', 'nada mais', 'Rua Reinaldo Pereira numero 274', 'posso ver o prejuizo?'], ['4/8/2022 18:26:30', 'Teste', 'cardapio pls', 'uma pizza de frango ', 'claro q nao kk', 'rua ufms 123', 'mostra ai qnto deu'], ['4/9/2022 2:11:26', 'Treino', 'Me veja o cardapio ', 'Quero uma pizza de presunto', 'nao quero', 'Rua ufms 171', 'consultar meu pedido']]\n"]},{"output_type":"execute_result","data":{"text/plain":["   conjunto                                       ver_cardapio  \\\n","0     Teste                      olá! tudo bem? É da pizzaria?   \n","1     Teste                    Boa noite, cardápio por favor ?   \n","2     Teste                                 Por favor, o menu.   \n","3     Teste                          coe, manda o menu de hoje   \n","4     Teste  tudo bom? pode me manda o link ou imagem do ca...   \n","..      ...                                                ...   \n","65   Treino                            Deixa eu ver o cardápio   \n","66    Teste                    Boa noite, poderia ver cardápio   \n","67    Teste                                Passa o cardápio ae   \n","68    Teste                                       cardapio pls   \n","69   Treino                                Me veja o cardapio    \n","\n","                                         fazer_pedido  \n","0      Legal, vou querer uma de bacon, mas sem cebola  \n","1                  Uma pizza de calabresa e uma coca.  \n","2          1 pizza de calabresa e uma pizza de frango  \n","3    quero uma pizza de frango e duas coca, faz favor  \n","4   quero uma pizza de calabresa, uma de bacon e u...  \n","..                                                ...  \n","65                         Uma de frango e duas cocas  \n","66  Eu vou querer uma pizza grande de frango e uma...  \n","67                   Vou querer uma pizza portuguesa   \n","68                               uma pizza de frango   \n","69                        Quero uma pizza de presunto  \n","\n","[70 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-1b802ffd-2128-40fb-bb4d-29d7e0cca51c\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>conjunto</th>\n","      <th>ver_cardapio</th>\n","      <th>fazer_pedido</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Teste</td>\n","      <td>olá! tudo bem? É da pizzaria?</td>\n","      <td>Legal, vou querer uma de bacon, mas sem cebola</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Teste</td>\n","      <td>Boa noite, cardápio por favor ?</td>\n","      <td>Uma pizza de calabresa e uma coca.</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Teste</td>\n","      <td>Por favor, o menu.</td>\n","      <td>1 pizza de calabresa e uma pizza de frango</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Teste</td>\n","      <td>coe, manda o menu de hoje</td>\n","      <td>quero uma pizza de frango e duas coca, faz favor</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Teste</td>\n","      <td>tudo bom? pode me manda o link ou imagem do ca...</td>\n","      <td>quero uma pizza de calabresa, uma de bacon e u...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>65</th>\n","      <td>Treino</td>\n","      <td>Deixa eu ver o cardápio</td>\n","      <td>Uma de frango e duas cocas</td>\n","    </tr>\n","    <tr>\n","      <th>66</th>\n","      <td>Teste</td>\n","      <td>Boa noite, poderia ver cardápio</td>\n","      <td>Eu vou querer uma pizza grande de frango e uma...</td>\n","    </tr>\n","    <tr>\n","      <th>67</th>\n","      <td>Teste</td>\n","      <td>Passa o cardápio ae</td>\n","      <td>Vou querer uma pizza portuguesa</td>\n","    </tr>\n","    <tr>\n","      <th>68</th>\n","      <td>Teste</td>\n","      <td>cardapio pls</td>\n","      <td>uma pizza de frango</td>\n","    </tr>\n","    <tr>\n","      <th>69</th>\n","      <td>Treino</td>\n","      <td>Me veja o cardapio</td>\n","      <td>Quero uma pizza de presunto</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>70 rows × 3 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1b802ffd-2128-40fb-bb4d-29d7e0cca51c')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-1b802ffd-2128-40fb-bb4d-29d7e0cca51c button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-1b802ffd-2128-40fb-bb4d-29d7e0cca51c');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":54}]},{"cell_type":"code","source":[""],"metadata":{"id":"z6cL3QRv5EaL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["intencoes = rows[0][2:4]\n","print(intencoes)\n","xtrain_global = []\n","ytrain_global = []\n","for intencao in intencoes:\n","    lintencao = df[df['conjunto']=='Treino'][intencao].values.tolist()\n","    xtrain_global += lintencao\n","    ytrain_global += [intencao]*len(lintencao)\n","\n","len(xtrain_global), len(ytrain_global)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BYWliwkVxQxH","executionInfo":{"status":"ok","timestamp":1652758078708,"user_tz":180,"elapsed":258,"user":{"displayName":"Walter Souza","userId":"13336398162492909212"}},"outputId":"d8df798a-5c37-4c5c-f648-8da0e72f2b29"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['ver_cardapio', 'fazer_pedido']\n"]},{"output_type":"execute_result","data":{"text/plain":["(116, 116)"]},"metadata":{},"execution_count":55}]},{"cell_type":"code","source":["xtest_global = []\n","ytest_global = []\n","for intencao in intencoes:\n","    lintencao = df[df['conjunto']=='Teste'][intencao].values.tolist()\n","    xtest_global += lintencao\n","    ytest_global += [intencao]*len(lintencao)\n","\n","len(xtest_global), len(ytest_global)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EhSWbm9UxShf","executionInfo":{"status":"ok","timestamp":1652758078974,"user_tz":180,"elapsed":2,"user":{"displayName":"Walter Souza","userId":"13336398162492909212"}},"outputId":"c33a08c5-d980-4aa9-9926-4864a70b463f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(24, 24)"]},"metadata":{},"execution_count":56}]},{"cell_type":"code","source":["import pandas as pd\n","ytrain, labels = pd.factorize(ytrain_global)\n","ytest, _ = pd.factorize(ytest_global)\n","xtrain = xtrain_global\n","xtest = xtest_global"],"metadata":{"id":"odWYi4pbzMP3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"-EEf3V7wz_aH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["xtrain[21]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"zR9LDnHtyfoG","executionInfo":{"status":"ok","timestamp":1652716565522,"user_tz":180,"elapsed":4,"user":{"displayName":"Walter Souza","userId":"13336398162492909212"}},"outputId":"cca27334-195c-4037-df31-809fa4fdf5c1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'manda uma fotinha do cardápio ai'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["ytrain[21]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HXp7zu7Py5g2","executionInfo":{"status":"ok","timestamp":1652716567831,"user_tz":180,"elapsed":223,"user":{"displayName":"Walter Souza","userId":"13336398162492909212"}},"outputId":"e7c2d38a-45ca-43e1-c2bd-60ff8cfc84c4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["import numpy as np\n","np.unique(ytrain)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TSf4phrB2ufz","executionInfo":{"status":"ok","timestamp":1652758084826,"user_tz":180,"elapsed":240,"user":{"displayName":"Walter Souza","userId":"13336398162492909212"}},"outputId":"dc606fd9-730b-4ea7-b53c-54f09bbd5a26"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 1])"]},"metadata":{},"execution_count":58}]},{"cell_type":"code","source":["# Define the maximum number of words to tokenize (DistilBERT can tokenize up to 512)\n","MAX_LENGTH = 128\n","\n","# Define function to encode text data in batches\n","def batch_encode(tokenizer, texts, batch_size=256, max_length=MAX_LENGTH):\n","    \"\"\"\"\"\"\"\"\"\n","    A function that encodes a batch of texts and returns the texts'\n","    corresponding encodings and attention masks that are ready to be fed \n","    into a pre-trained transformer model.\n","    \n","    Input:\n","        - tokenizer:   Tokenizer object from the PreTrainedTokenizer Class\n","        - texts:       List of strings where each string represents a text\n","        - batch_size:  Integer controlling number of texts in a batch\n","        - max_length:  Integer controlling max number of words to tokenize in a given text\n","    Output:\n","        - input_ids:       sequence of texts encoded as a tf.Tensor object\n","        - attention_mask:  the texts' attention mask encoded as a tf.Tensor object\n","    \"\"\"\"\"\"\"\"\"\n","    \n","    input_ids = []\n","    attention_mask = []\n","    \n","    for i in range(0, len(texts), batch_size):\n","        batch = texts[i:i+batch_size]\n","        inputs = tokenizer.batch_encode_plus(batch,\n","                                             max_length=max_length,\n","                                             padding='longest', #implements dynamic padding\n","                                             truncation=True,\n","                                             return_attention_mask=True,\n","                                             return_token_type_ids=False\n","                                             )\n","        input_ids.extend(inputs['input_ids'])\n","        attention_mask.extend(inputs['attention_mask'])\n","    \n","    \n","    return torch.tensor(input_ids), torch.tensor(attention_mask)\n","    \n","    \n","# Encode X_train\n","X_train_ids, X_train_attention = batch_encode(tokenizer, xtrain)\n","\n","# Encode X_test\n","X_test_ids, X_test_attention = batch_encode(tokenizer, xtest)"],"metadata":{"id":"9M4DBzFMy7I8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train_ids.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aeLV38tHE6UD","executionInfo":{"status":"ok","timestamp":1652758401756,"user_tz":180,"elapsed":248,"user":{"displayName":"Walter Souza","userId":"13336398162492909212"}},"outputId":"cbce8283-40fd-455f-c2b7-7ee1588ee57a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([116, 25])"]},"metadata":{},"execution_count":74}]},{"cell_type":"code","source":["from transformers import DistilBertTokenizerFast, DistilBertModel, DistilBertConfig\n","import torch\n","\n","configuration = DistilBertConfig()\n","tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\n","model = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n","\n","model.last_linear = torch.nn.Linear(configuration.dim, 120)\n","layer_blocks = model.transformer.layer"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fIBvOsv7GWLF","executionInfo":{"status":"ok","timestamp":1652759723568,"user_tz":180,"elapsed":1622,"user":{"displayName":"Walter Souza","userId":"13336398162492909212"}},"outputId":"28dec823-25b8-4322-da7d-9b7eeb6fd18c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_projector.weight']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}]},{"cell_type":"code","source":["print(layer_blocks[0].attention)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":287},"id":"N7PTHtoVKSSR","executionInfo":{"status":"error","timestamp":1652759989129,"user_tz":180,"elapsed":293,"user":{"displayName":"Walter Souza","userId":"13336398162492909212"}},"outputId":"ddac5e62-41f0-40ec-845c-7268a8b69d9c"},"execution_count":null,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-108-f4b07a8eafd4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_blocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_attention\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: forward() missing 3 required positional arguments: 'key', 'value', and 'mask'"]}]},{"cell_type":"code","source":["device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","\n","model.to('cpu')\n","#model.train()\n","\n","X_train_ids.to(device)\n","X_train_attention.to(device)\n","\n","\n","#outputs = model(X_train_ids, attention_mask=X_train_attention)\n","\n","x = X_train_ids.to(device)\n","\n","for layer in layer_blocks:\n","    x = layer(x)\n","\n","    print(x.shape)\n","\n","print(outputs.last_hidden_state.shape)\n","input()\n","\n","input()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":380},"id":"OHovL4sjFlmt","executionInfo":{"status":"error","timestamp":1652759750777,"user_tz":180,"elapsed":4,"user":{"displayName":"Walter Souza","userId":"13336398162492909212"}},"outputId":"8eb79e89-06f9-48ef-e874-e3bea3b887d3"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-99-51b45a6e04fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayer_blocks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, attn_mask, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattn_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m         )\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query, key, value, mask, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    188\u001b[0m             seq_length, dim) Contextualized layer. Optional: only if `output_attentions=True`\n\u001b[1;32m    189\u001b[0m         \"\"\"\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m         \u001b[0mk_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;31m# assert dim == self.dim, f'Dimensions do not match: {dim} input vs {self.dim} configured'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"BnJxowoAJedW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')"],"metadata":{"id":"NvnsdoyFEWJs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_encodings = tokenizer(xtrain, truncation=True, padding=True)\n","test_encodings = tokenizer(xtest, truncation=True, padding=True)"],"metadata":{"id":"MXcI-BtU0aAg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_encodings[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bePWoKaN025t","executionInfo":{"status":"ok","timestamp":1652758249345,"user_tz":180,"elapsed":247,"user":{"displayName":"Walter Souza","userId":"13336398162492909212"}},"outputId":"1b916daf-2a4e-4f11-8306-00185644e929"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Encoding(num_tokens=25, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])"]},"metadata":{},"execution_count":71}]},{"cell_type":"code","source":["class IMDbDataset(torch.utils.data.Dataset):\n","    def __init__(self, tokenizer, inputs, labels):\n","        self.inputs = inputs\n","        self.encodings = tokenizer(inputs, truncation=True, padding=True)\n","        self.labels = labels\n","\n","    def __getitem__(self, idx):\n","        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        item['inputs'] = self.inputs[idx]\n","        item['labels'] = torch.tensor(self.labels[idx])\n","        return item\n","\n","    def __len__(self):\n","        return len(self.labels)"],"metadata":{"id":"kH_CLLjO04n3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataset = IMDbDataset(tokenizer, xtrain, ytrain)\n","test_dataset = IMDbDataset(tokenizer, xtest, ytest)"],"metadata":{"id":"I_n7Ac751WK9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataloaders = {}\n","dataloaders['training'] = torch.utils.data.DataLoader(train_dataset, num_workers=3, batch_size=5, shuffle=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yd8JUrvhlk7G","executionInfo":{"status":"ok","timestamp":1652717914289,"user_tz":180,"elapsed":3,"user":{"displayName":"Walter Souza","userId":"13336398162492909212"}},"outputId":"57c29ed7-0f73-4287-bdde-7cca88101eda"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]}]},{"cell_type":"code","source":["dataloaders['training'].dataset.labels"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2E5wP5TIvhTR","executionInfo":{"status":"ok","timestamp":1652719257292,"user_tz":180,"elapsed":218,"user":{"displayName":"Walter Souza","userId":"13336398162492909212"}},"outputId":"bc24a001-da57-451d-dd27-eb15b0807126"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n","       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","       1, 1, 1, 1, 1, 1])"]},"metadata":{},"execution_count":101}]},{"cell_type":"code","source":["data_iterator = dataloaders['training']\n","\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","\n","model.to(device)\n","# model.train()\n","\n","for i,out in enumerate(data_iterator):\n","    input_ = out['inputs']\n","    class_labels = out['labels']\n","    \n","    input_ids = out['input_ids'].to(device)\n","    attention_mask = out['attention_mask'].to(device)\n","    labels = out['labels'].to(device)\n","    \n","    print(len(input_))\n","    print(class_labels.shape)\n","    print(input_ids.shape)\n","    print(attention_mask.shape)\n","    print(labels.shape)\n","    \n","    outputs = model(input_ids, attention_mask=attention_mask)\n","    print(outputs.last_hidden_state.shape)\n","    input()\n","\n","    input()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":695},"id":"2xfMA_k8l7AN","executionInfo":{"status":"error","timestamp":1652718747597,"user_tz":180,"elapsed":753123,"user":{"displayName":"Walter Souza","userId":"13336398162492909212"}},"outputId":"80b68d53-4ce4-4ba7-8203-77c2bca71a52"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["5\n","torch.Size([5])\n","torch.Size([5, 25])\n","torch.Size([5, 25])\n","torch.Size([5])\n","torch.Size([5, 25, 768])\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    624\u001b[0m         \"\"\"\n\u001b[0;32m--> 625\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: ","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-85-cf3d6fe51c5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_hidden_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["from transformers import DistilBertTokenizerFast, DistilBertModel\n","import torch\n","\n","tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\n","model = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")"],"metadata":{"id":"TBaKKQo818W3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tqdm.notebook import tqdm\n","from torch.utils.data import DataLoader\n","from transformers import DistilBertForSequenceClassification, AdamW\n","\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","\n","model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')\n","model.to(device)\n","model.train()\n","\n","train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n","\n","optim = AdamW(model.parameters(), lr=5e-5)\n","\n","for epoch in range(3):\n","    for batch in tqdm(train_loader):\n","        optim.zero_grad()\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","        labels = batch['labels'].to(device)\n","        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n","        loss = outputs[0]\n","        loss.backward()\n","        optim.step()\n","        optim.zero_grad()\n","model.eval()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["c591e8b4ba7e4fcaae1e687251c2024a","140db0f00f094aa9a0366a25de31ec7d","cf5c8984d9da4c468df321222d8b245f","79d5bdf6f10d445facf6d7514e5b0655","0df305c4e15b499685f9925c6e3b1b30","c7983943f08f4f33a6774403ed01cb89","9a866f4317694648bbe46a403af42ee1","16ef4e42881c4742acc8cbc4b2a45ef9","50c606699adb495d8ca6253a42884420","c9fc9f0b20df46c9a170e66482866b9c","141142cc0e4b431baa940d203858886e","d8da1df56bda44a983c473585dd51878","ee31c60ca93c407a87a9c2f096f68b6a","8e1ff3df11e249f989718c533f541f75","f849a4487f8b409ea1031cc46dfa3237","460660433f1c4ffa9c1afa947f460528","5ab638a0a2aa4e6483a9fa51ab0bfec9","212075ade9104fdba8faa11571c7db23","374064586a7e45629a66193999deba2c","7109e6c11a7544f5a29cf27b6b3be862","ab32b8c0759c403794f66adbeef7db38","f224787e10e045c4b0c8c4fd73f4578c","d33ba95fd8634f26bfc21ac7fb4bf362","2a298c59678f47b29556495e91f022f6","193c6d4c1b5442d0a4d1ddadea9fe04d","4f9b706c0a10441091a13b43d8672f64","f785a4f05f854e3bb14e9a7975b7a082","d010c935b0264da49c9740fd39e94ac1","4809f92fd12a4c15aeaa4e93b3ecf689","478683b02bc84d6188ed973288818156","0f666bf3c2cd44cfb982d4db6e74c3cf","b38ecebdb174465a8ba080f89f83b732","22a3098385c34a158097becc3b5a419b"]},"id":"tI4P3h7_1h8H","executionInfo":{"status":"ok","timestamp":1652654783037,"user_tz":180,"elapsed":56176,"user":{"displayName":"Walter Souza","userId":"13336398162492909212"}},"outputId":"90160538-9d9d-404c-f07b-7c7764cd81b7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/8 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c591e8b4ba7e4fcaae1e687251c2024a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/8 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d8da1df56bda44a983c473585dd51878"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/8 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d33ba95fd8634f26bfc21ac7fb4bf362"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["DistilBertForSequenceClassification(\n","  (distilbert): DistilBertModel(\n","    (embeddings): Embeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (transformer): Transformer(\n","      (layer): ModuleList(\n","        (0): TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","            (activation): GELUActivation()\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (1): TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","            (activation): GELUActivation()\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (2): TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","            (activation): GELUActivation()\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (3): TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","            (activation): GELUActivation()\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (4): TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","            (activation): GELUActivation()\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (5): TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","            (activation): GELUActivation()\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","      )\n","    )\n","  )\n","  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n","  (dropout): Dropout(p=0.2, inplace=False)\n",")"]},"metadata":{},"execution_count":88}]},{"cell_type":"code","source":["import os\n","\n","# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n","\n","output_dir = './model_save/'\n","\n","# Create output directory if needed\n","if not os.path.exists(output_dir):\n","    os.makedirs(output_dir)\n","\n","print(\"Saving model to %s\" % output_dir)\n","\n","# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n","# They can then be reloaded using `from_pretrained()`\n","model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n","model_to_save.save_pretrained(output_dir)\n","tokenizer.save_pretrained(output_dir)\n","\n","# Good practice: save your training arguments together with the trained model\n","#torch.save(args, os.path.join(output_dir, 'training_args.bin'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mCBjBK-g1oNx","executionInfo":{"status":"ok","timestamp":1652654837960,"user_tz":180,"elapsed":2121,"user":{"displayName":"Walter Souza","userId":"13336398162492909212"}},"outputId":"97cff936-4ab2-490c-c2cb-e58f175a9ca5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Saving model to ./model_save/\n"]},{"output_type":"execute_result","data":{"text/plain":["('./model_save/tokenizer_config.json',\n"," './model_save/special_tokens_map.json',\n"," './model_save/vocab.txt',\n"," './model_save/added_tokens.json',\n"," './model_save/tokenizer.json')"]},"metadata":{},"execution_count":89}]},{"cell_type":"code","source":["import torch.nn.functional as F\n","\n","test_loader = DataLoader(test_dataset, batch_size=16)\n","\n","def accuracy(outputs, labels):\n","    _, preds = torch.max(outputs, dim=1)\n","    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n","\n","def validation(validation_dataloader):\n","  with torch.no_grad():\n","    loss_val_list = []\n","    preds_list = []\n","    accuracy_list = []\n","    accuracy_sum = 0\n","    for batch in tqdm(validation_dataloader):\n","      #print(batch.keys())\n","      input_ids = batch['input_ids'].to(device)\n","      attention_mask = batch['attention_mask'].to(device)\n","      labels = batch['labels'].to(device)\n","\n","      outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n","      loss = outputs[0]\n","      logits = F.softmax(outputs[1], dim=1)   # Taking the softmax of output\n","      _,preds = torch.max(logits, dim=1)      # Taking the predictions of our batch\n","      acc = accuracy(logits,labels)           # Calculating the accuracy of current batch\n","      accuracy_sum += acc                     # Taking sum of all the accuracies of all the batches. This sum will be divided by batch length to get mean accuracy for validation dataset\n","\n","      loss_val_list.append(loss)\n","      preds_list.append(preds)\n","      accuracy_list.append(acc)\n","\n","  mean_accuracy = accuracy_sum / len(validation_dataloader)\n","  return mean_accuracy"],"metadata":{"id":"hRzHjOXa54a9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["validation(test_loader)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["2f2c8fa2c6294a73b54e194df7be7c94","78d7e7b4826c42eb8755108ad0eed681","dff3a065bd0c49e394946fa906d97172","c8fe86d9aad243b1a9fc8a505b02fd92","6bed5e8da0c1481bb8a1f3bc71d7c6fb","0e64d364a8ba4396b82e6d009f6f2e85","4d2e2ef8aebb413ebab8870e852522ef","50464d5e3c7b4104acaa857ffca4b751","fe71d598ce204e1e86827deec4df395a","560e747510484799a56ae662adf7a49e","bbe83d2e063a4f479e93cb6fc0dc88ef"]},"id":"PDi64hRK6AYi","executionInfo":{"status":"ok","timestamp":1652655007179,"user_tz":180,"elapsed":1102,"user":{"displayName":"Walter Souza","userId":"13336398162492909212"}},"outputId":"d463b03f-b588-4f89-9745-84fae48a23ef"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f2c8fa2c6294a73b54e194df7be7c94"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["tensor(1.)"]},"metadata":{},"execution_count":98}]},{"cell_type":"code","source":["review = ['opa, manda o cardapio ai pro pai', 'vou querer uma de calabresa']\n","review_tokenised = tokenizer(review, truncation=True, padding=True)\n","review_dataset = IMDbDataset(review_tokenised, [0])\n","review_loader = DataLoader(review_dataset, batch_size=2)"],"metadata":{"id":"vtNiJe676EuU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with torch.no_grad():\n","  for batch in review_loader : \n","    input_ids = batch['input_ids'].to(device)\n","    attention_mask = batch['attention_mask'].to(device)\n","    labels = batch['labels'].to(device)\n","    prediction = model(input_ids, attention_mask=attention_mask, labels=labels)\n","    logits = F.softmax(prediction[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o-j6Jgq664YK","executionInfo":{"status":"ok","timestamp":1652655208138,"user_tz":180,"elapsed":2,"user":{"displayName":"Walter Souza","userId":"13336398162492909212"}},"outputId":"5cdd19f5-b0b6-4d9a-8188-d1b56abc0234"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  import sys\n"]}]},{"cell_type":"code","source":["_,preds = torch.max(logits, dim=1) "],"metadata":{"id":"G-kZ0Avw693P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["preds.item()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":165},"id":"adV3jEIn7AEU","executionInfo":{"status":"error","timestamp":1652655209205,"user_tz":180,"elapsed":4,"user":{"displayName":"Walter Souza","userId":"13336398162492909212"}},"outputId":"c180c7cb-8f6d-4bf7-8fca-bf80be63e9ea"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-119-6e161d6602b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"]}]},{"cell_type":"code","source":["labels"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KO0sBywp7Bcj","executionInfo":{"status":"ok","timestamp":1652655199756,"user_tz":180,"elapsed":2,"user":{"displayName":"Walter Souza","userId":"13336398162492909212"}},"outputId":"6978519d-7f05-406d-f9fa-f0c9e591fdd9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0])"]},"metadata":{},"execution_count":115}]},{"cell_type":"code","source":[""],"metadata":{"id":"4AByp8co7HZp"},"execution_count":null,"outputs":[]}]}